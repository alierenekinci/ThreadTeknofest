{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bbbfd86",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46426d96-f2e5-4611-9d29-014b9f6d7223",
   "metadata": {
    "tags": []
   },
   "source": [
    "Faydalandığımız kaynak\n",
    "- https://www.kaggle.com/code/akshitrai/chatbot-jarvis\n",
    "- https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8643b4-de90-4d6f-b445-799d94a237f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np \n",
    "import string\n",
    "from unicode_tr import unicode_tr\n",
    "from nltk.corpus import stopwords\n",
    "from snowballstemmer import TurkishStemmer\n",
    "from nltk import ngrams\n",
    "import pandas as pd \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fab2e4-e620-4db7-b10a-b9733d7e2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:\\Users\\alierenekinci\\Desktop\\Project\\ThreadTeknofest\\veri'\n",
    "\n",
    "def yukle():\n",
    "    liste = os.listdir(path)\n",
    "    final_path = path + \"\\\\\" + liste[-1]\n",
    "    print(final_path)\n",
    "    with open(final_path, encoding='utf-8') as f:\n",
    "        veri = json.load(f)\n",
    "    return veri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230e62b2-bae3-4e06-90f9-3958667fa291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = yukle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d25087-db95-495e-b2cf-9371f0b6aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, responses = [],[]\n",
    "\n",
    "\n",
    "for veri_ in df_:\n",
    "    for i, j in enumerate(df_[veri_]):\n",
    "        for k,l in enumerate(j[\"patterns\"]):\n",
    "            questions.append(l)\n",
    "            responses.append(df_[veri_][i][\"responses\"][0])\n",
    "        # for k,l in enumerate(j[\"responses\"]):\n",
    "        #     responses.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08535ed7-0561-4edb-a059-bf30ced34b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([questions,responses]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc404a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"clf\", RandomForestClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Parameters to use for grid search. Uncommenting more parameters will give\n",
    "# better exploring power but will increase processing time in a combinatorial\n",
    "# way\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5,),\n",
    "    'vect__max_features': (10000,),\n",
    "    # \"vect__ngram_range\": ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    'tfidf__use_idf': (False,),\n",
    "    'tfidf__norm': ('l2',),\n",
    "    \"clf__n_estimators\": (100,),\n",
    "    \"clf__criterion\" : (\"gini\",),\n",
    "    # \"clf__max_depth\" : (1, 2, 5, 7),\n",
    "    \"clf__min_samples_leaf\" : (1,),\n",
    "    # \"clf__max_features\" : (\"sqrt\", \"log2\", None)\n",
    "}\n",
    "\n",
    "# Find the best parameters for both the feature extraction and the\n",
    "# classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=10, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(df[0],df[1])\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b3c6c-5a36-4391-bb18-368f2e8d765a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifierModel = Pipeline([\n",
    "    ('bow',CountVectorizer(max_df=0.5, max_features=10000)),\n",
    "    ('tfidf',TfidfTransformer(norm=\"l2\", use_idf=False)),\n",
    "    ('classifier', RandomForestClassifier(criterion=\"gini\", min_samples_leaf=1, n_estimators=100))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271cbb3-cfc5-431c-a85e-46def63438f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifierModel.fit(df[0],df[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d931ac9-a3ed-420d-b41c-8112cf67e46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metin_onisle(metin):\n",
    "    kucuk_harfli_metin = unicode_tr(metin).lower()\n",
    "    istenen_karakterler = set(list(' abcdefghijklmnopqrstuvwxyzâçîöüğış0123456789'))\n",
    "    harfler = list(kucuk_harfli_metin)\n",
    "    harfler = [k if k in istenen_karakterler else ' ' for k in harfler]\n",
    "    temiz_dokuman = \"\".join(kucuk_harfli_metin)\n",
    "    temiz_dokuman_kelimeleri = temiz_dokuman.split(' ')\n",
    "    temiz_dokuman_kelimeleri = [kelime for kelime in temiz_dokuman_kelimeleri if len(kelime) > 0]\n",
    "    stopWords = set(stopwords.words('turkish'))\n",
    "    temiz_dokuman_kelimeleri = [\"\" if kelime in stopWords else kelime for kelime in temiz_dokuman_kelimeleri]\n",
    "    temiz_dokuman_kelimeleri = \" \".join(temiz_dokuman_kelimeleri).replace(\"  \", \" \").split()\n",
    "    turkStem=TurkishStemmer()\n",
    "    temiz_dokuman_kelimeleri = [turkStem.stemWord(kelime) for kelime in temiz_dokuman_kelimeleri]\n",
    "    n = 2\n",
    "    bigrams = ngrams(temiz_dokuman_kelimeleri, n)\n",
    "    bigramstr = map(''.join, bigrams)\n",
    "    ngram = \" \".join(list(bigramstr))\n",
    "    temiz_dokuman = \" \".join(temiz_dokuman_kelimeleri) + \" \" +  \"\".join(ngram)\n",
    "    return temiz_dokuman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19595214",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([metin_onisle(\"BaşkentKart\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b848c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "probs = model.predict_proba([\"BaşkentKart\"])\n",
    "sorted( zip( RandomForestClassifierModel.classes_, probs[0] ), key=lambda x:x[1] )[-n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634de48-e222-4b70-9ab6-c114bfae42fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifierModel.predict_proba([metin_onisle(\"Teleferik\")])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb53259",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifierModel.predict([metin_onisle(\"Teleferik\")])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65c8f8-352b-4edf-a148-d5efe22d7553",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifierModel.predict([metin_onisle(\"Başkent Kartın Aidat Ücreti\")])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8288e4cb-7bee-4a7f-96c6-76e8f1c0651d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifierModel.predict([metin_onisle(\"Cenaze / defin işlemi\")])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ffc41c-a053-471c-8b15-4819466afc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifierModel.predict([metin_onisle(\"Öğrencilerin ücretsitaşındığ hat\")])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aee2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../ankarabbHibritChatbot/RandomForestClassifierModel.pickle', 'wb') as handle:\n",
    "    pickle.dump(RandomForestClassifierModel, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18fc817",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1df0eea4252ede35fe93c0f35960b9445b1332ca42ea871324a9eba8a70bf54f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
